{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7db4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa71de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.linalg\n",
    "import os\n",
    "\n",
    "import torch\n",
    "used_device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff94b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Graspot.ST_utils import Cal_Spatial_Net, mapping_accuracy_ot, mapping_accuracy_in, batch_entropy_mixing_score, silhouette, avg_silhouette_width_batch\n",
    "from Graspot.OT_utils import distance_matrix, unbalanced_ot\n",
    "from Graspot.train import norm_and_center_coordinates, train_Graspot, train_Graspot_Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7c1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151669', '151670']\n",
      "151669\n",
      "------Calculating spatial graph...\n",
      "The graph contains 21194 edges, 3661 cells.\n",
      "5.7891 neighbors per cell on average.\n",
      "151670\n",
      "------Calculating spatial graph...\n",
      "The graph contains 20370 edges, 3498 cells.\n",
      "5.8233 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151669','151670']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de757a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eff67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2156, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2156, heads=1)\n",
      ")\n",
      "Pretrain with STAGATE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [00:09<00:00, 20.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [00:51<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, initial = True, Couple = None, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3b81d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6905757011319644"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_entropy_mixing_score(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['batch_name']))\n",
    "#0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbf3278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5828511938452721"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['Ground Truth']))\n",
    "#0.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b1682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9522981643676758"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_silhouette_width_batch(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['batch_name']),np.array(adata_concat.obs['Ground Truth']))\n",
    "#0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da5b2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151670', '151671']\n",
      "151670\n",
      "------Calculating spatial graph...\n",
      "The graph contains 20370 edges, 3498 cells.\n",
      "5.8233 neighbors per cell on average.\n",
      "151671\n",
      "------Calculating spatial graph...\n",
      "The graph contains 24052 edges, 4110 cells.\n",
      "5.8521 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151670','151671']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8bd6c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c68c4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2144, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2144, heads=1)\n",
      ")\n",
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [00:57<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, initial = True, Couple = None, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95e44d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875445680151334"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_entropy_mixing_score(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['batch_name']))\n",
    "#0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0037ddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5228031203150749"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['Ground Truth']))\n",
    "#0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79af9283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.901580810546875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_silhouette_width_batch(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['batch_name']),np.array(adata_concat.obs['Ground Truth']))\n",
    "#0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e74ff39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151671', '151672']\n",
      "151671\n",
      "------Calculating spatial graph...\n",
      "The graph contains 24052 edges, 4110 cells.\n",
      "5.8521 neighbors per cell on average.\n",
      "151672\n",
      "------Calculating spatial graph...\n",
      "The graph contains 23382 edges, 4015 cells.\n",
      "5.8237 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151671','151672']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f7f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d45d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2171, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2171, heads=1)\n",
      ")\n",
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [01:05<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, initial = True, Couple = None, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b97a46af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6907469475993032"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_entropy_mixing_score(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['batch_name']))\n",
    "#0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9f52f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5739313811063766"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['Ground Truth']))\n",
    "#0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86824974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907818078994751"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_silhouette_width_batch(adata_concat.obsm['Graspot'],np.array(adata_concat.obs['batch_name']),np.array(adata_concat.obs['Ground Truth']))\n",
    "#0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f1040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151669', '151670', '151671', '151672']\n",
      "151669\n",
      "------Calculating spatial graph...\n",
      "The graph contains 21194 edges, 3661 cells.\n",
      "5.7891 neighbors per cell on average.\n",
      "151670\n",
      "------Calculating spatial graph...\n",
      "The graph contains 20370 edges, 3498 cells.\n",
      "5.8233 neighbors per cell on average.\n",
      "151671\n",
      "------Calculating spatial graph...\n",
      "The graph contains 24052 edges, 4110 cells.\n",
      "5.8521 neighbors per cell on average.\n",
      "151672\n",
      "------Calculating spatial graph...\n",
      "The graph contains 23382 edges, 4015 cells.\n",
      "5.8237 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151669','151670','151671','151672']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0f048b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6b0c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(946, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 946, heads=1)\n",
      ")\n",
      "Pretrain with STAGATE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [00:13<00:00, 15.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [00:49<00:00,  4.07it/s]\n",
      "100%|███████████████| 200/200 [01:02<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1), (2, 3)]\n",
    "adata_concat, tran_list = train_Graspot(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, initial = True, device=used_device)\n",
    "#adata_concat, tran_list = train_Graspot_Sub(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        #Batch_list=Batch_list,  initial = True, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef286a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8997983\n",
      "0.84878707\n"
     ]
    }
   ],
   "source": [
    "accuracy_ot=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    accuracy_ot.append(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))\n",
    "    print(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e71eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9033733562035449\n",
      "0.8483188044831881\n"
     ]
    }
   ],
   "source": [
    "accuracy_in=[]\n",
    "matching_plt=[]\n",
    "getMax_plt=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    result1 = pd.DataFrame(tran_list[iters].cpu().detach().numpy())\n",
    "    if tran_list[iters].shape[0] < tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=1)\n",
    "        matching = np.array([np.arange(result1.shape[0]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        #np.put_along_axis(getMax,tran_list[iters].cpu().detach().numpy().argmax(1)[:,None],1,axis=1)\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][0])\n",
    "            y = int(matching[:,k][1])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=0)\n",
    "        matching = np.array([np.arange(result1.shape[1]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][1])\n",
    "            y = int(matching[:,k][0])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    \n",
    "    accuracy_in.append(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))\n",
    "    print(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5101d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8617829268370529\n",
      "0.7319159822640117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "#Batch_list[1].obs['Ground Truth'][matching_plt[0][1]]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i, j = comb[0], comb[1]\n",
    "    if tran_list[iters].shape[0] < tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[i].obs['Ground Truth'],Batch_list[j].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[j].obs['Ground Truth'],Batch_list[i].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8179952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151670', '151671']\n",
      "151670\n",
      "------Calculating spatial graph...\n",
      "The graph contains 20370 edges, 3498 cells.\n",
      "5.8233 neighbors per cell on average.\n",
      "151671\n",
      "------Calculating spatial graph...\n",
      "The graph contains 24052 edges, 4110 cells.\n",
      "5.8521 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151670','151671']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73d06fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d823e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'Layer_1':1, 'Layer_2':2, 'Layer_3':3, 'Layer_4':4, 'Layer_5':5, 'Layer_6':6, 'WM':7}\n",
    "data1 = np.array(Batch_list[0].obs['Ground Truth'].map(mapping_dict))\n",
    "data2 = np.array(Batch_list[1].obs['Ground Truth'].map(mapping_dict))\n",
    "\n",
    "gamma = 0.5\n",
    "\n",
    "DM = np.ones((len(data1), len(data2)))\n",
    "for i in range(len(data1)):\n",
    "    for j in range(len(data2)):\n",
    "        if data1[i] == data2[j]:\n",
    "            DM[i][j] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60344ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2144, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2144, heads=1)\n",
      ")\n",
      "Pretrain with STAGATE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:09<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:56<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot_Sub(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, Couple=None, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3166d0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69886893\n"
     ]
    }
   ],
   "source": [
    "accuracy_ot=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    accuracy_ot.append(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))\n",
    "    print(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b348321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7012578616352201\n"
     ]
    }
   ],
   "source": [
    "accuracy_in=[]\n",
    "matching_plt=[]\n",
    "getMax_plt=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    result1 = pd.DataFrame(tran_list[iters].cpu().detach().numpy())\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=1)\n",
    "        matching = np.array([np.arange(result1.shape[0]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        #np.put_along_axis(getMax,tran_list[iters].cpu().detach().numpy().argmax(1)[:,None],1,axis=1)\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][0])\n",
    "            y = int(matching[:,k][1])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=0)\n",
    "        matching = np.array([np.arange(result1.shape[1]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][1])\n",
    "            y = int(matching[:,k][0])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    \n",
    "    accuracy_in.append(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))\n",
    "    print(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68a0a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4662222720933047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "#Batch_list[1].obs['Ground Truth'][matching_plt[0][1]]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i, j = comb[0], comb[1]\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[i].obs['Ground Truth'],Batch_list[j].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[j].obs['Ground Truth'],Batch_list[i].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a23318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2144, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2144, heads=1)\n",
      ")\n",
      "Pretrain with STAGATE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:09<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [01:00<00:00,  3.31it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot_Sub(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, Couple=DM, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc963f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81332463\n"
     ]
    }
   ],
   "source": [
    "accuracy_ot=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    accuracy_ot.append(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))\n",
    "    print(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04122e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8053173241852487\n"
     ]
    }
   ],
   "source": [
    "accuracy_in=[]\n",
    "matching_plt=[]\n",
    "getMax_plt=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    result1 = pd.DataFrame(tran_list[iters].cpu().detach().numpy())\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=1)\n",
    "        matching = np.array([np.arange(result1.shape[0]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        #np.put_along_axis(getMax,tran_list[iters].cpu().detach().numpy().argmax(1)[:,None],1,axis=1)\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][0])\n",
    "            y = int(matching[:,k][1])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=0)\n",
    "        matching = np.array([np.arange(result1.shape[1]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][1])\n",
    "            y = int(matching[:,k][0])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    \n",
    "    accuracy_in.append(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))\n",
    "    print(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87380d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5751643695040616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "#Batch_list[1].obs['Ground Truth'][matching_plt[0][1]]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i, j = comb[0], comb[1]\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[i].obs['Ground Truth'],Batch_list[j].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[j].obs['Ground Truth'],Batch_list[i].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcb76cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151669', '151670']\n",
      "151669\n",
      "------Calculating spatial graph...\n",
      "The graph contains 21194 edges, 3661 cells.\n",
      "5.7891 neighbors per cell on average.\n",
      "151670\n",
      "------Calculating spatial graph...\n",
      "The graph contains 20370 edges, 3498 cells.\n",
      "5.8233 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151669','151670']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a821274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33693bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'Layer_1':1, 'Layer_2':2, 'Layer_3':3, 'Layer_4':4, 'Layer_5':5, 'Layer_6':6, 'WM':7}\n",
    "data1 = np.array(Batch_list[0].obs['Ground Truth'].map(mapping_dict))\n",
    "data2 = np.array(Batch_list[1].obs['Ground Truth'].map(mapping_dict))\n",
    "\n",
    "gamma = 0.5\n",
    "\n",
    "DM = np.ones((len(data1), len(data2)))\n",
    "for i in range(len(data1)):\n",
    "    for j in range(len(data2)):\n",
    "        if data1[i] == data2[j]:\n",
    "            DM[i][j] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37aab38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2156, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2156, heads=1)\n",
      ")\n",
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [00:54<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, initial=True, Couple=DM, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca951f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9147077\n"
     ]
    }
   ],
   "source": [
    "accuracy_ot=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    accuracy_ot.append(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))\n",
    "    print(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8551a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9139508290451687\n"
     ]
    }
   ],
   "source": [
    "accuracy_in=[]\n",
    "matching_plt=[]\n",
    "getMax_plt=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    result1 = pd.DataFrame(tran_list[iters].cpu().detach().numpy())\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=1)\n",
    "        matching = np.array([np.arange(result1.shape[0]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        #np.put_along_axis(getMax,tran_list[iters].cpu().detach().numpy().argmax(1)[:,None],1,axis=1)\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][0])\n",
    "            y = int(matching[:,k][1])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=0)\n",
    "        matching = np.array([np.arange(result1.shape[1]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][1])\n",
    "            y = int(matching[:,k][0])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    \n",
    "    accuracy_in.append(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))\n",
    "    print(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3409018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8725726914245223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "#Batch_list[1].obs['Ground Truth'][matching_plt[0][1]]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i, j = comb[0], comb[1]\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[i].obs['Ground Truth'],Batch_list[j].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[j].obs['Ground Truth'],Batch_list[i].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995734df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['151671', '151672']\n",
      "151671\n",
      "------Calculating spatial graph...\n",
      "The graph contains 24052 edges, 4110 cells.\n",
      "5.8521 neighbors per cell on average.\n",
      "151672\n",
      "------Calculating spatial graph...\n",
      "The graph contains 23382 edges, 4015 cells.\n",
      "5.8237 neighbors per cell on average.\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "Batch_list = []\n",
    "adj_list = []\n",
    "section_ids = ['151671','151672']\n",
    "#section_ids = ['151673','151674']\n",
    "print(section_ids)\n",
    "\n",
    "for section_id in section_ids:\n",
    "    print(section_id)\n",
    "    input_dir = os.path.join('data/', section_id)\n",
    "    adata = sc.read_visium(path=input_dir, count_file=section_id + '_filtered_feature_bc_matrix.h5', load_images=True)\n",
    "    adata.var_names_make_unique(join=\"++\")\n",
    "\n",
    "    # read the annotation\n",
    "    Ann_df = pd.read_csv(os.path.join(input_dir, section_id + '_truth.txt'), sep='\\t', header=None, index_col=0)\n",
    "    Ann_df.columns = ['Ground Truth']\n",
    "    Ann_df[Ann_df.isna()] = \"unknown\"\n",
    "    adata.obs['Ground Truth'] = Ann_df.loc[adata.obs_names, 'Ground Truth'].astype('category')\n",
    "\n",
    "    # make spot name unique\n",
    "    adata.obs_names = [x+'_'+section_id for x in adata.obs_names]\n",
    "\n",
    "    # Constructing the spatial network\n",
    "    Cal_Spatial_Net(adata, rad_cutoff=150) # the spatial network are saved in adata.uns[‘adj’]\n",
    "    # STAligner.Stats_Spatial_Net(adata) # plot the number of spatial neighbors\n",
    "\n",
    "    # Normalization\n",
    "    sc.pp.highly_variable_genes(adata, flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "    adj_list.append(adata.uns['adj'])\n",
    "    Batch_list.append(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e715039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "adata_concat = ad.concat(Batch_list, label=\"slice_name\", keys=section_ids)\n",
    "adata_concat.obs['Ground Truth'] = adata_concat.obs['Ground Truth'].astype('category')\n",
    "adata_concat.obs[\"batch_name\"] = adata_concat.obs[\"slice_name\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0b2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'Layer_1':1, 'Layer_2':2, 'Layer_3':3, 'Layer_4':4, 'Layer_5':5, 'Layer_6':6, 'WM':7}\n",
    "data1 = np.array(Batch_list[0].obs['Ground Truth'].map(mapping_dict))\n",
    "data2 = np.array(Batch_list[1].obs['Ground Truth'].map(mapping_dict))\n",
    "\n",
    "gamma = 0.5\n",
    "\n",
    "DM = np.ones((len(data1), len(data2)))\n",
    "for i in range(len(data1)):\n",
    "    for j in range(len(data2)):\n",
    "        if data1[i] == data2[j]:\n",
    "            DM[i][j] = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1974c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAligner(\n",
      "  (conv1): GATConv(2171, 512, heads=1)\n",
      "  (conv2): GATConv(512, 30, heads=1)\n",
      "  (conv3): GATConv(30, 512, heads=1)\n",
      "  (conv4): GATConv(512, 2171, heads=1)\n",
      ")\n",
      "Train with STAligner...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 200/200 [01:09<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_comb = [(0, 1)]\n",
    "adata_concat, tran_list = train_Graspot(adata_concat, verbose=True, knn_neigh = 100, n_epochs = 200, iter_comb = iter_comb,\n",
    "                                                        Batch_list=Batch_list, initial=True, Couple=DM, device=used_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58924ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8520578\n"
     ]
    }
   ],
   "source": [
    "accuracy_ot=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    accuracy_ot.append(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))\n",
    "    print(mapping_accuracy_ot(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], tran_list[iters].cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a73178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851307596513076\n"
     ]
    }
   ],
   "source": [
    "accuracy_in=[]\n",
    "matching_plt=[]\n",
    "getMax_plt=[]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i,j=comb[0],comb[1]\n",
    "    result1 = pd.DataFrame(tran_list[iters].cpu().detach().numpy())\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=1)\n",
    "        matching = np.array([np.arange(result1.shape[0]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        #np.put_along_axis(getMax,tran_list[iters].cpu().detach().numpy().argmax(1)[:,None],1,axis=1)\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][0])\n",
    "            y = int(matching[:,k][1])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        matching_index = np.argmax(result1.to_numpy(),axis=0)\n",
    "        matching = np.array([np.arange(result1.shape[1]),matching_index])\n",
    "        getMax = np.zeros_like(tran_list[iters].cpu().detach().numpy())\n",
    "        for k in range(matching.shape[1]):\n",
    "            x = int(matching[:,k][1])\n",
    "            y = int(matching[:,k][0])\n",
    "            getMax[x][y] = 1\n",
    "        matching_plt.append(matching)\n",
    "        getMax_plt.append(getMax)\n",
    "    \n",
    "    accuracy_in.append(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))\n",
    "    print(mapping_accuracy_in(Batch_list[i].obs['Ground Truth'], Batch_list[j].obs['Ground Truth'], getMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41569ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7340198291841303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "#Batch_list[1].obs['Ground Truth'][matching_plt[0][1]]\n",
    "for iters,comb in enumerate(iter_comb):\n",
    "    i, j = comb[0], comb[1]\n",
    "    if tran_list[iters].shape[0] <= tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[i].obs['Ground Truth'],Batch_list[j].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大\n",
    "    if tran_list[iters].shape[0] > tran_list[iters].shape[1]:\n",
    "        print(adjusted_rand_score(Batch_list[j].obs['Ground Truth'],Batch_list[i].obs['Ground Truth'][matching_plt[iters][1]]))#第一个小第二个大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc2624d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
